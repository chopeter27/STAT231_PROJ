---
title: "Data Summary"
author: "Andrea and Peter"
date: "11/25/2018"
output: html_document
---

Load necessary packages
```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Tidying data packages
library(ggplot2) #dynamic graphics
library(tidyr) #data tidying
library(readr) #reading in csv file
library(dplyr) #manipulating datasets

# Text Data Extraction and Manipulation
library(tm) #text mining
library(tidytext) #text tidying
library(SnowballC) #stemming

# Decision Tree Modeling Packages
library(rpart) #tree modeling for classification
library(partykit) #tree modeling
library(pROC) #area under the curve

# Don't Include this Package
# library(qdap) #text data manipulation

set.seed(123)

```

Basic Data Exploration:
```{r}
# Loading the dataset
fake <- read_csv("fake.csv") #all fake
real <- read_csv("Articles.csv") #all real
new_ds <- read_csv("data.csv") #combination of real and fake
fake_type <- c("fake", "satire", "bias", "bs", "conspiracy", "state", "junksci", "hate")
real_type <- c("sports", "business")

# Merging the datasets and removing unnecessary columns
real <- real %>% 
  mutate(binary_type = ifelse(NewsType %in% fake_type, 0, 1)) #now fake = 0 and real = 1
fake <- fake %>% 
  mutate(binary_type = ifelse(type %in% fake_type, 0, 1)) #now fake = 0 and real = 1
new_ds <- new_ds %>% 
  filter(Label == 1)
real <- full_join(real, new_ds, by = c("Heading" = "Headline", "Article" = "Body", "binary_type" = "Label"))
real <- real %>% 
  mutate(id = as.character(seq(1:4564))) %>%
  mutate(realtype = "real")

combined <- full_join(fake, real, by = c("text" = "Article", "title" = "Heading", "uuid" = "id", "binary_type" = "binary_type", "type" = "realtype")) %>% 
  select(uuid, binary_type, type, title, text)


# Making a tidy dataset where we have the the words in their own column for facilitated data analysis and exploration
tidy_combined <- combined %>%
  unnest_tokens(word, text)
```

```{r}
#See how many observations are in each type of fake news
combined %>% 
  group_by(type) %>% 
  summarize(n = n())
typetotals <- combined %>% 
  group_by(type) %>% 
  summarize(n = n())
```

```{r}
#what are the most common words for each basic emotion?
#we will use the nrc dictionary so these emotions are the following: anger, fear, anticipation, trust, surprise, sadness, joy, and disgust

#anger
nrc_anger <- get_sentiments("nrc") %>% 
  filter(sentiment == "anger")

tidy_combined %>%
  inner_join(nrc_anger) %>%
  count(word, sort = TRUE)

#fear
nrc_fear <- get_sentiments("nrc") %>% 
  filter(sentiment == "fear")

tidy_combined %>%
  inner_join(nrc_fear) %>%
  count(word, sort = TRUE)

#anticipation
nrc_anticipation <- get_sentiments("nrc") %>% 
  filter(sentiment == "anticipation")

tidy_combined %>%
  inner_join(nrc_anticipation) %>%
  count(word, sort = TRUE)

#trust
nrc_trust <- get_sentiments("nrc") %>% 
  filter(sentiment == "trust")

tidy_combined %>%
  inner_join(nrc_trust) %>%
  count(word, sort = TRUE)

#surprise
nrc_surprise <- get_sentiments("nrc") %>% 
  filter(sentiment == "surprise")

tidy_combined %>%
  inner_join(nrc_surprise) %>%
  count(word, sort = TRUE)

#sadness
nrc_sadness <- get_sentiments("nrc") %>% 
  filter(sentiment == "sadness")

tidy_combined %>%
  inner_join(nrc_sadness) %>%
  count(word, sort = TRUE)

#joy
nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_combined %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

#disgust
nrc_disgust <- get_sentiments("nrc") %>% 
  filter(sentiment == "disgust")

tidy_combined %>%
  inner_join(nrc_disgust) %>%
  count(word, sort = TRUE)
```

```{r}
#find net sentiment for each type of fake news documented in the dataset using the bing lexicon
#note that some types, such as bs (>400000), have more corresponding observations than other types, such as fake(<400)
combined_sentiment <- tidy_combined %>%
  inner_join(get_sentiments("bing")) %>%
  count(type, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
combined_sentiment

#plot the sentiment score for each type of fake news
ggplot(combined_sentiment, aes(x = type, y = sentiment)) + geom_col() + labs(title = "Sentiment Score for All News", x = "Type of News", y = "Sentiment Score")
```

```{r}
#we can also get the sentiment score on a scale of -5 to 5 from the afinn lexicon
afinn <- tidy_combined %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(type) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")
afinn

```

```{r}
#positive and negative words in nrc lexicon
get_sentiments("nrc") %>% 
     filter(sentiment %in% c("positive", 
                             "negative")) %>% 
  count(sentiment)

#positive and negative words in bing lexicon
get_sentiments("bing") %>% 
  count(sentiment)

#both lexicons have more negative words than positive words, but the bing lexicon has a higher ratio of negative to positive words than the nrc lexon. This can contribute to the results we see in our data
```

```{r}
#counting most frequently appearing words and which sentiment they correspond to (positive or negative) from the bing lexicon
bing_word_counts <- tidy_combined %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
bing_word_counts

bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  ggtitle("Positive and Negative Word Frequency") +
  labs(y = "Frequency of Word",
       x = NULL) +
  theme(text = element_text(size=30),
        axis.text.x = element_text(angle=90, hjust=1)) +
  coord_flip()
```

```{r}
#wordcloud with most frqeuently appearing words
tidy_combined %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(words = word, freq = n, max.words = 100, min.freq = 1, random.order=FALSE, rot.per = 0.35, colors = brewer.pal(8, "Dark2")))

#wordcloud faceted into positive and negative with color (blue = negative, red = positive)
tidy_combined %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("blue", "orange"),
                   max.words = 100)
```

Now, it is time to start the machine learning aspect of the project.
```{r}
# #let's use the bing lexicon to add a sentiment column to the tidy_fake dataset
# tidy_combined_b <- tidy_combined %>%
#   inner_join(get_sentiments("bing"))

#using afinn lexicon to append the sentiment score of each word to tidy_fake 
tidy_combined_a <- tidy_combined %>% 
  inner_join(get_sentiments("afinn"))
```

```{r}
# #calculate average afinn sentiment score for positive and negative words
# tidy_combined_a %>%
#   select(score, sentiment) %>%
#   group_by(sentiment) %>%
#   summarise(n = n(), avgscore = sum(score) / n)
```

```{r}
#categorize article as positive or negative overall
tidy_combined_final <- tidy_combined_a %>%
  select(uuid, score, binary_type) %>% 
  group_by(uuid) %>%
  summarise(n_words = n(), avgscore = sum(score) / n_words, 
            type = mean(binary_type), 
            positive_score = sum(score[score > 0]), 
            negative_score = sum(score[score < 0]),
            n_positive = sum(score > 0),
            n_negative = sum(score < 0)
            ) %>%
  mutate(articlesent = ifelse(avgscore < 0, "Negative", "Positive")) %>% 
  mutate(txt_type = as.factor(type)) %>%
  select(-type)
tidy_combined_final

tidy_combined_final %>% 
  filter(txt_type == 0) %>% 
  summarise(n_negative = n())

# Decision Tree Training Process
n <- nrow(tidy_combined_final)
train_id <- sample(1:n, size = round(n * 0.8))
train <- tidy_combined_final[train_id,]
test <- tidy_combined_final[-train_id,]


tree <- rpart(txt_type ~ avgscore + n_words + n_positive + n_negative + negative_score + positive_score, data = train)
plot(as.party(tree))
tree

saveRDS(tree, file = "tree.rds")
saveRDS(train, file = "train.rds")
prediction <- predict(tree, test)

test <- test %>% 
  mutate(prediction = prediction[1])
roc_obj <- roc(test$txt_type, test$prediction)
auc(roc_obj)
plot(roc_obj)
```
Based on this tree, we can see that none of the predictors (average score, number of words, number of positive words, and number of number of negative words) are userful in predicting whether an article is real or fake.

Why is this true? Below, we will do some exploration using visualizations to display the poor relationship between our predictions and type of article (real or fake).

```{r}
#Making a logistic regression model for txt_type
mylogit <- glm(txt_type ~ avgscore + n_words + n_positive, data = tidy_combined_final, family = "binomial")
#Omitted n_negative because this is colinear with n_negative
summary(mylogit)
plot(mylogit)
```

```{r}
ggplot(tidy_combined_final, aes(n_words, as.numeric(txt_type)-1, color=articlesent)) +
  stat_smooth(method="glm", formula=y~x, alpha=0.2, size=2, aes(fill=articlesent)) +
  geom_point(position=position_jitter(height=0.03, width=0)) +
  xlab("Number of Words") + 
  ylab("Probability (Real)") + 
  ggtitle("Probability of a Real Article Based on Number of Words and Article Sentiment") +
  scale_color_discrete(name = "Article Sentiment") +
  scale_fill_discrete(guide = FALSE)
```

```{r}
ggplot(tidy_combined_final, aes(x = avgscore, fill = txt_type)) +
  geom_histogram() +
  xlab("Average Score") + 
  ylab("Count") + 
  ggtitle("Histogram of Average Sentiment Score by News Type (Real and Fake)") +
  scale_fill_discrete(name = "Real or Fake News", labels = c("Fake", "Real"))
```

```{r}
ggplot(tidy_combined_final, aes(x=txt_type, y=avgscore)) + 
  geom_boxplot() +
  xlab("Type of News (Real or Fake)") +
  ylab("Average Score") +
  ggtitle("Average Sentiment Scores in Real and Fake News") +
  ggplot2::annotate(geom = "text", label = "Here, 0 represents fake news and 1 represents real news", x = 1.5, y = 3, size = 3.3)

ggplot(tidy_combined_final, aes(x=txt_type, y=n_words)) + 
  geom_boxplot() +
  xlab("Type of News (Real or Fake)") +
  ylab("Number of Words in Article") +
  ggtitle("Number of Words in Real and Fake News") +
  theme(text = element_text(size=30),
        axis.text.x = element_text(angle=90, hjust=1))

ggplot(tidy_combined_final, aes(x=txt_type, y=n_negative)) + 
  geom_boxplot() +
  xlab("Type of News (Real or Fake)") +
  ylab("Number of Negative Words") +
  ggtitle("Number of Negative Words in Real and Fake News") +
  theme(text = element_text(size=30),
        axis.text.x = element_text(angle=90, hjust=1))

ggplot(tidy_combined_final, aes(x=txt_type, y=n_positive)) + 
  geom_boxplot() +
  xlab("Type of News (Real or Fake)") +
  ylab("Number of Positive Words") +
  ggtitle("Number of Positive Words in Real and Fake News") +
  theme(text = element_text(size=30),
        axis.text.x = element_text(angle=90, hjust=1))

ggplot(tidy_combined_final, aes(x=txt_type, y=negative_score)) + 
  geom_boxplot() +
  xlab("Type of News (Real or Fake)") +
  ylab("Sum of Negative Word Scores") +
  ggtitle("Sum of Negative Word Scores in Real and Fake News") +
  theme(text = element_text(size=30),
        axis.text.x = element_text(angle=90, hjust=1))

ggplot(tidy_combined_final, aes(x=txt_type, y=positive_score)) + 
  geom_boxplot() +
  xlab("Type of News (Real or Fake)") +
  ylab("Sum of Positive Word Scores") +
  ggtitle("Sum of Positive Word Scores in Real and Fake News") +
  theme(text = element_text(size=30),
        axis.text.x = element_text(angle=90, hjust=1))
```
